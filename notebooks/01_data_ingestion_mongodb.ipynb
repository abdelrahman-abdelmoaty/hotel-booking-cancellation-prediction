{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Ingestion into MongoDB\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Setting up MongoDB Atlas connection\n",
        "2. Loading hotel booking dataset into MongoDB\n",
        "3. Creating indexes for efficient querying\n",
        "4. Demonstrating MongoDB aggregation queries\n",
        "\n",
        "## Dataset\n",
        "- **Source**: Hotel Booking Demand Dataset from Kaggle\n",
        "- **Records**: 119,390 hotel bookings\n",
        "- **Features**: 32 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install pymongo dnspython python-dotenv pandas tqdm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import ConnectionFailure\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.append('/content/src') if 'google.colab' in str(get_ipython()) else sys.path.append('../src')\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: MongoDB Atlas Setup\n",
        "\n",
        "**Instructions:**\n",
        "1. Go to https://www.mongodb.com/cloud/atlas and create a free account\n",
        "2. Create a new cluster (free tier M0)\n",
        "3. Create a database user with read/write permissions\n",
        "4. Whitelist your IP address (use 0.0.0.0/0 for Colab)\n",
        "5. Get your connection string\n",
        "6. Replace the connection string below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MongoDB Connection Configuration\n",
        "# Replace with your MongoDB Atlas connection string\n",
        "MONGODB_URI = \"mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority\"\n",
        "DB_NAME = \"hotel_bookings\"\n",
        "COLLECTION_NAME = \"bookings\"\n",
        "\n",
        "# Alternative: Load from environment variable\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# MONGODB_URI = os.getenv('MONGODB_URI')\n",
        "\n",
        "print(\"MongoDB configuration set\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test MongoDB connection\n",
        "try:\n",
        "    client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)\n",
        "    # Test connection\n",
        "    client.admin.command('ping')\n",
        "    print(\"✓ Successfully connected to MongoDB Atlas\")\n",
        "    \n",
        "    # List databases\n",
        "    print(f\"\\nAvailable databases: {client.list_database_names()}\")\n",
        "    \n",
        "except ConnectionFailure as e:\n",
        "    print(f\"✗ Failed to connect to MongoDB: {e}\")\n",
        "    print(\"\\nPlease check your connection string and network settings.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Dataset\n",
        "\n",
        "**Note**: Download the dataset from [Kaggle](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand) and upload it to Colab or mount Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "# Option 1: From uploaded file in Colab\n",
        "csv_path = \"/content/hotel_bookings.csv\"\n",
        "\n",
        "# Option 2: From Google Drive (uncomment if using)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# csv_path = \"/content/drive/MyDrive/hotel_bookings.csv\"\n",
        "\n",
        "# Option 3: From local path (for local Jupyter)\n",
        "# csv_path = \"../data/hotel_bookings.csv\"\n",
        "\n",
        "try:\n",
        "    # Read first few rows to check\n",
        "    df_sample = pd.read_csv(csv_path, nrows=5)\n",
        "    print(\"✓ Dataset found!\")\n",
        "    print(f\"Columns: {df_sample.columns.tolist()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    display(df_sample.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"✗ Dataset not found. Please upload the CSV file to Colab or update the path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Data into MongoDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to database\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# Check if collection already exists and has data\n",
        "existing_count = collection.count_documents({})\n",
        "if existing_count > 0:\n",
        "    print(f\"⚠ Collection already contains {existing_count} documents.\")\n",
        "    response = input(\"Do you want to drop and reload? (yes/no): \")\n",
        "    if response.lower() == 'yes':\n",
        "        collection.drop()\n",
        "        print(\"✓ Collection dropped\")\n",
        "    else:\n",
        "        print(\"Skipping data load. Using existing data.\")\n",
        "        load_data = False\n",
        "else:\n",
        "    load_data = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data into MongoDB in chunks\n",
        "if load_data:\n",
        "    print(\"Loading data into MongoDB...\")\n",
        "    chunk_size = 10000\n",
        "    total_inserted = 0\n",
        "    \n",
        "    # Read CSV in chunks\n",
        "    for chunk in tqdm(pd.read_csv(csv_path, chunksize=chunk_size), desc=\"Loading chunks\"):\n",
        "        # Convert DataFrame to list of dictionaries\n",
        "        records = chunk.to_dict('records')\n",
        "        # Insert into MongoDB\n",
        "        try:\n",
        "            result = collection.insert_many(records)\n",
        "            total_inserted += len(result.inserted_ids)\n",
        "        except Exception as e:\n",
        "            print(f\"Error inserting chunk: {e}\")\n",
        "    \n",
        "    print(f\"\\n✓ Successfully inserted {total_inserted} documents into MongoDB\")\n",
        "else:\n",
        "    total_inserted = collection.count_documents({})\n",
        "    print(f\"Using existing {total_inserted} documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Indexes\n",
        "\n",
        "Indexes improve query performance significantly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create indexes for efficient querying\n",
        "indexes = [\n",
        "    (\"is_canceled\", 1),  # Target variable - most important for filtering\n",
        "    (\"hotel\", 1),  # Hotel type filter\n",
        "    (\"arrival_date_year\", 1),  # Year filter\n",
        "    (\"arrival_date_month\", 1),  # Month filter\n",
        "    (\"country\", 1),  # Country filter\n",
        "    (\"market_segment\", 1),  # Market segment filter\n",
        "    (\"deposit_type\", 1),  # Deposit type filter\n",
        "    (\"customer_type\", 1),  # Customer type filter\n",
        "]\n",
        "\n",
        "print(\"Creating indexes...\")\n",
        "for field, direction in indexes:\n",
        "    try:\n",
        "        collection.create_index([(field, direction)])\n",
        "        print(f\"✓ Created index on {field}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Failed to create index on {field}: {e}\")\n",
        "\n",
        "# List all indexes\n",
        "print(\"\\nCurrent indexes:\")\n",
        "for index in collection.list_indexes():\n",
        "    print(f\"  - {index['name']}: {index.get('key', {})}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Data and Basic Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get collection statistics\n",
        "total_docs = collection.count_documents({})\n",
        "cancelled = collection.count_documents({\"is_canceled\": 1})\n",
        "not_cancelled = collection.count_documents({\"is_canceled\": 0})\n",
        "cancellation_rate = (cancelled / total_docs * 100) if total_docs > 0 else 0\n",
        "\n",
        "print(\"=== Collection Statistics ===\")\n",
        "print(f\"Total documents: {total_docs:,}\")\n",
        "print(f\"Cancelled bookings: {cancelled:,} ({cancellation_rate:.2f}%)\")\n",
        "print(f\"Not cancelled bookings: {not_cancelled:,} ({100-cancellation_rate:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample a few documents to verify structure\n",
        "print(\"\\n=== Sample Documents ===\")\n",
        "sample_docs = list(collection.find().limit(2))\n",
        "for i, doc in enumerate(sample_docs, 1):\n",
        "    print(f\"\\nDocument {i}:\")\n",
        "    for key, value in list(doc.items())[:10]:  # Show first 10 fields\n",
        "        print(f\"  {key}: {value}\")\n",
        "    if len(doc) > 10:\n",
        "        print(f\"  ... and {len(doc) - 10} more fields\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: MongoDB Aggregation Queries\n",
        "\n",
        "Demonstrating MongoDB's powerful aggregation framework for data analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query 1: Cancellation rate by hotel type\n",
        "print(\"=== Cancellation Rate by Hotel Type ===\")\n",
        "pipeline1 = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$hotel\",\n",
        "            \"total_bookings\": {\"$sum\": 1},\n",
        "            \"cancelled\": {\"$sum\": \"$is_canceled\"},\n",
        "            \"not_cancelled\": {\"$sum\": {\"$subtract\": [1, \"$is_canceled\"]}}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"hotel\": \"$_id\",\n",
        "            \"total_bookings\": 1,\n",
        "            \"cancelled\": 1,\n",
        "            \"not_cancelled\": 1,\n",
        "            \"cancellation_rate\": {\n",
        "                \"$multiply\": [\n",
        "                    {\"$divide\": [\"$cancelled\", \"$total_bookings\"]},\n",
        "                    100\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\"$sort\": {\"cancellation_rate\": -1}}\n",
        "]\n",
        "\n",
        "results1 = list(collection.aggregate(pipeline1))\n",
        "df_hotel = pd.DataFrame(results1)\n",
        "display(df_hotel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query 2: Cancellation rate by deposit type\n",
        "print(\"=== Cancellation Rate by Deposit Type ===\")\n",
        "pipeline2 = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$deposit_type\",\n",
        "            \"total_bookings\": {\"$sum\": 1},\n",
        "            \"cancelled\": {\"$sum\": \"$is_canceled\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"deposit_type\": \"$_id\",\n",
        "            \"total_bookings\": 1,\n",
        "            \"cancelled\": 1,\n",
        "            \"cancellation_rate\": {\n",
        "                \"$multiply\": [\n",
        "                    {\"$divide\": [\"$cancelled\", \"$total_bookings\"]},\n",
        "                    100\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\"$sort\": {\"cancellation_rate\": -1}}\n",
        "]\n",
        "\n",
        "results2 = list(collection.aggregate(pipeline2))\n",
        "df_deposit = pd.DataFrame(results2)\n",
        "display(df_deposit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query 3: Top 10 countries by booking count\n",
        "print(\"=== Top 10 Countries by Booking Count ===\")\n",
        "pipeline3 = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$country\",\n",
        "            \"total_bookings\": {\"$sum\": 1},\n",
        "            \"cancelled\": {\"$sum\": \"$is_canceled\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"country\": \"$_id\",\n",
        "            \"total_bookings\": 1,\n",
        "            \"cancelled\": 1,\n",
        "            \"cancellation_rate\": {\n",
        "                \"$multiply\": [\n",
        "                    {\"$divide\": [\"$cancelled\", \"$total_bookings\"]},\n",
        "                    100\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\"$sort\": {\"total_bookings\": -1}},\n",
        "    {\"$limit\": 10}\n",
        "]\n",
        "\n",
        "results3 = list(collection.aggregate(pipeline3))\n",
        "df_countries = pd.DataFrame(results3)\n",
        "display(df_countries)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query 4: Average lead time by market segment\n",
        "print(\"=== Average Lead Time by Market Segment ===\")\n",
        "pipeline4 = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$market_segment\",\n",
        "            \"avg_lead_time\": {\"$avg\": \"$lead_time\"},\n",
        "            \"total_bookings\": {\"$sum\": 1},\n",
        "            \"cancelled\": {\"$sum\": \"$is_canceled\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"market_segment\": \"$_id\",\n",
        "            \"avg_lead_time\": {\"$round\": [\"$avg_lead_time\", 2]},\n",
        "            \"total_bookings\": 1,\n",
        "            \"cancellation_rate\": {\n",
        "                \"$multiply\": [\n",
        "                    {\"$divide\": [\"$cancelled\", \"$total_bookings\"]},\n",
        "                    100\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\"$sort\": {\"avg_lead_time\": -1}}\n",
        "]\n",
        "\n",
        "results4 = list(collection.aggregate(pipeline4))\n",
        "df_segment = pd.DataFrame(results4)\n",
        "display(df_segment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Export Data for Next Steps\n",
        "\n",
        "Export data from MongoDB to CSV for use in subsequent notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all data from MongoDB to pandas DataFrame\n",
        "print(\"Loading data from MongoDB...\")\n",
        "cursor = collection.find()\n",
        "df_mongodb = pd.DataFrame(list(cursor))\n",
        "\n",
        "# Remove MongoDB _id field\n",
        "if '_id' in df_mongodb.columns:\n",
        "    df_mongodb = df_mongodb.drop('_id', axis=1)\n",
        "\n",
        "print(f\"✓ Loaded {len(df_mongodb)} records\")\n",
        "print(f\"Shape: {df_mongodb.shape}\")\n",
        "print(f\"\\nColumns: {df_mongodb.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to CSV for next notebook (optional - can also load directly from MongoDB)\n",
        "output_path = \"/content/hotel_bookings_from_mongodb.csv\"\n",
        "df_mongodb.to_csv(output_path, index=False)\n",
        "print(f\"✓ Data exported to {output_path}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n=== Data Summary ===\")\n",
        "print(df_mongodb.info())\n",
        "print(\"\\n=== First few rows ===\")\n",
        "display(df_mongodb.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✓ Data successfully loaded into MongoDB Atlas\n",
        "✓ Indexes created for efficient querying\n",
        "✓ Aggregation queries demonstrated\n",
        "✓ Data ready for EDA and ML processing\n",
        "\n",
        "**Next Steps**: Proceed to `02_eda_analysis.ipynb` for exploratory data analysis.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
