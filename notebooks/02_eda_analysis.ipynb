{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2: Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on the hotel booking dataset to:\n",
        "1. Understand data structure and quality\n",
        "2. Identify patterns and relationships\n",
        "3. Discover factors influencing cancellations\n",
        "4. Prepare insights for feature engineering\n",
        "\n",
        "## Objectives\n",
        "- Univariate analysis of all features\n",
        "- Bivariate analysis with target variable\n",
        "- Correlation analysis\n",
        "- Missing value analysis\n",
        "- Key insights extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install pandas numpy matplotlib seaborn plotly -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n",
        "\n",
        "Load data from CSV file or MongoDB (from previous notebook).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Load from CSV (if you have the file)\n",
        "csv_path = \"/content/hotel_bookings.csv\"  # Colab path\n",
        "# csv_path = \"../data/hotel_bookings.csv\"  # Local path\n",
        "\n",
        "# Option 2: Load from MongoDB (from previous notebook)\n",
        "# from pymongo import MongoClient\n",
        "# MONGODB_URI = \"your_connection_string\"\n",
        "# client = MongoClient(MONGODB_URI)\n",
        "# db = client[\"hotel_bookings\"]\n",
        "# collection = db[\"bookings\"]\n",
        "# cursor = collection.find()\n",
        "# df = pd.DataFrame(list(cursor))\n",
        "# if '_id' in df.columns:\n",
        "#     df = df.drop('_id', axis=1)\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"✓ Data loaded from CSV: {csv_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"CSV not found. Please load from MongoDB or update path.\")\n",
        "    df = None\n",
        "\n",
        "if df is not None:\n",
        "    print(f\"\\nDataset shape: {df.shape}\")\n",
        "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic information\n",
        "print(\"=== Dataset Information ===\")\n",
        "print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
        "print(f\"\\nColumn names and types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nFirst few rows:\")\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing values analysis\n",
        "print(\"=== Missing Values Analysis ===\")\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing.index,\n",
        "    'Missing Count': missing.values,\n",
        "    'Missing Percentage': missing_pct.values\n",
        "}).sort_values('Missing Count', ascending=False)\n",
        "\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
        "if len(missing_df) > 0:\n",
        "    display(missing_df)\n",
        "    print(f\"\\nTotal columns with missing values: {len(missing_df)}\")\n",
        "else:\n",
        "    print(\"✓ No missing values found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"=== Statistical Summary (Numerical Features) ===\")\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "display(df[numerical_cols].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical features summary\n",
        "print(\"=== Categorical Features Summary ===\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_cols[:5]:  # Show first 5\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target distribution\n",
        "target_col = 'is_canceled'\n",
        "cancellation_counts = df[target_col].value_counts()\n",
        "cancellation_pct = df[target_col].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"=== Target Variable Distribution ===\")\n",
        "print(f\"Not Cancelled (0): {cancellation_counts[0]:,} ({cancellation_pct[0]:.2f}%)\")\n",
        "print(f\"Cancelled (1): {cancellation_counts[1]:,} ({cancellation_pct[1]:.2f}%)\")\n",
        "print(f\"Total: {len(df):,}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot\n",
        "axes[0].bar(['Not Cancelled', 'Cancelled'], cancellation_counts.values, \n",
        "            color=['#2ecc71', '#e74c3c'], alpha=0.7)\n",
        "axes[0].set_title('Cancellation Count', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Count')\n",
        "for i, v in enumerate(cancellation_counts.values):\n",
        "    axes[0].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(cancellation_counts.values, labels=['Not Cancelled', 'Cancelled'],\n",
        "           autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
        "axes[1].set_title('Cancellation Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Univariate Analysis - Numerical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key numerical features to analyze\n",
        "key_numerical = ['lead_time', 'adr', 'stays_in_weekend_nights', \n",
        "                 'stays_in_week_nights', 'adults', 'children', 'babies',\n",
        "                 'previous_cancellations', 'previous_bookings_not_canceled']\n",
        "\n",
        "# Filter to existing columns\n",
        "key_numerical = [col for col in key_numerical if col in df.columns]\n",
        "\n",
        "# Distribution plots\n",
        "n_cols = 3\n",
        "n_rows = (len(key_numerical) + n_cols - 1) // n_cols\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5*n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(key_numerical):\n",
        "    axes[i].hist(df[col].dropna(), bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[i].set_title(f'{col} Distribution', fontweight='bold')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Hide extra subplots\n",
        "for i in range(len(key_numerical), len(axes)):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for key numerical features\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "features_to_plot = ['lead_time', 'adr', 'stays_in_weekend_nights', 'stays_in_week_nights']\n",
        "for i, col in enumerate(features_to_plot):\n",
        "    if col in df.columns:\n",
        "        row = i // 2\n",
        "        col_idx = i % 2\n",
        "        axes[row, col_idx].boxplot(df[col].dropna(), vert=True)\n",
        "        axes[row, col_idx].set_title(f'{col} Box Plot', fontweight='bold')\n",
        "        axes[row, col_idx].set_ylabel(col)\n",
        "        axes[row, col_idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Univariate Analysis - Categorical Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key categorical features\n",
        "key_categorical = ['hotel', 'meal', 'market_segment', 'distribution_channel',\n",
        "                   'deposit_type', 'customer_type', 'reservation_status']\n",
        "\n",
        "key_categorical = [col for col in key_categorical if col in df.columns]\n",
        "\n",
        "# Bar plots for categorical features\n",
        "n_cols = 2\n",
        "n_rows = (len(key_categorical) + n_cols - 1) // n_cols\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 5*n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(key_categorical):\n",
        "    value_counts = df[col].value_counts().head(10)\n",
        "    axes[i].barh(range(len(value_counts)), value_counts.values, color='coral', alpha=0.7)\n",
        "    axes[i].set_yticks(range(len(value_counts)))\n",
        "    axes[i].set_yticklabels(value_counts.index)\n",
        "    axes[i].set_title(f'{col} Distribution', fontweight='bold')\n",
        "    axes[i].set_xlabel('Count')\n",
        "    axes[i].invert_yaxis()\n",
        "\n",
        "# Hide extra subplots\n",
        "for i in range(len(key_categorical), len(axes)):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Bivariate Analysis - Cancellation by Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancellation rate by hotel type\n",
        "print(\"=== Cancellation Rate by Hotel Type ===\")\n",
        "hotel_cancel = df.groupby('hotel')['is_canceled'].agg(['count', 'sum', 'mean']).reset_index()\n",
        "hotel_cancel.columns = ['hotel', 'total_bookings', 'cancelled', 'cancellation_rate']\n",
        "hotel_cancel['cancellation_rate'] = hotel_cancel['cancellation_rate'] * 100\n",
        "display(hotel_cancel)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = ax.bar(hotel_cancel['hotel'], hotel_cancel['cancellation_rate'], \n",
        "              color=['#3498db', '#e74c3c'], alpha=0.7)\n",
        "ax.set_title('Cancellation Rate by Hotel Type', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Cancellation Rate (%)')\n",
        "ax.set_xlabel('Hotel Type')\n",
        "for i, (bar, rate) in enumerate(zip(bars, hotel_cancel['cancellation_rate'])):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "           f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancellation rate by deposit type\n",
        "print(\"=== Cancellation Rate by Deposit Type ===\")\n",
        "deposit_cancel = df.groupby('deposit_type')['is_canceled'].agg(['count', 'sum', 'mean']).reset_index()\n",
        "deposit_cancel.columns = ['deposit_type', 'total_bookings', 'cancelled', 'cancellation_rate']\n",
        "deposit_cancel['cancellation_rate'] = deposit_cancel['cancellation_rate'] * 100\n",
        "deposit_cancel = deposit_cancel.sort_values('cancellation_rate', ascending=False)\n",
        "display(deposit_cancel)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars = ax.barh(deposit_cancel['deposit_type'], deposit_cancel['cancellation_rate'],\n",
        "              color='coral', alpha=0.7)\n",
        "ax.set_title('Cancellation Rate by Deposit Type', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Cancellation Rate (%)')\n",
        "for i, (bar, rate) in enumerate(zip(bars, deposit_cancel['cancellation_rate'])):\n",
        "    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
        "           f'{rate:.1f}%', ha='left', va='center', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancellation rate by customer type\n",
        "print(\"=== Cancellation Rate by Customer Type ===\")\n",
        "customer_cancel = df.groupby('customer_type')['is_canceled'].agg(['count', 'sum', 'mean']).reset_index()\n",
        "customer_cancel.columns = ['customer_type', 'total_bookings', 'cancelled', 'cancellation_rate']\n",
        "customer_cancel['cancellation_rate'] = customer_cancel['cancellation_rate'] * 100\n",
        "customer_cancel = customer_cancel.sort_values('cancellation_rate', ascending=False)\n",
        "display(customer_cancel)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = ax.bar(customer_cancel['customer_type'], customer_cancel['cancellation_rate'],\n",
        "             color='steelblue', alpha=0.7)\n",
        "ax.set_title('Cancellation Rate by Customer Type', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Cancellation Rate (%)')\n",
        "ax.set_xlabel('Customer Type')\n",
        "plt.xticks(rotation=45)\n",
        "for bar, rate in zip(bars, customer_cancel['cancellation_rate']):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "           f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lead time vs cancellation\n",
        "print(\"=== Lead Time Analysis ===\")\n",
        "df['lead_time_category'] = pd.cut(df['lead_time'], \n",
        "                                  bins=[0, 30, 90, 180, 365, np.inf],\n",
        "                                  labels=['0-30', '31-90', '91-180', '181-365', '365+'])\n",
        "\n",
        "lead_cancel = df.groupby('lead_time_category')['is_canceled'].agg(['count', 'sum', 'mean']).reset_index()\n",
        "lead_cancel.columns = ['lead_time_category', 'total_bookings', 'cancelled', 'cancellation_rate']\n",
        "lead_cancel['cancellation_rate'] = lead_cancel['cancellation_rate'] * 100\n",
        "display(lead_cancel)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars = ax.bar(lead_cancel['lead_time_category'].astype(str), \n",
        "             lead_cancel['cancellation_rate'], color='mediumpurple', alpha=0.7)\n",
        "ax.set_title('Cancellation Rate by Lead Time Category', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Cancellation Rate (%)')\n",
        "ax.set_xlabel('Lead Time (days)')\n",
        "for bar, rate in zip(bars, lead_cancel['cancellation_rate']):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "           f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix for numerical features\n",
        "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if 'is_canceled' in numerical_features:\n",
        "    corr_matrix = df[numerical_features].corr()\n",
        "    \n",
        "    # Focus on correlation with target\n",
        "    target_corr = corr_matrix['is_canceled'].sort_values(ascending=False)\n",
        "    print(\"=== Correlation with Target Variable (is_canceled) ===\")\n",
        "    display(target_corr)\n",
        "    \n",
        "    # Heatmap\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "                center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title('Correlation Matrix - Numerical Features', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top features correlated with cancellation\n",
        "print(\"=== Top 10 Features Most Correlated with Cancellation ===\")\n",
        "top_corr = target_corr.drop('is_canceled').abs().sort_values(ascending=False).head(10)\n",
        "display(pd.DataFrame({\n",
        "    'Feature': top_corr.index,\n",
        "    'Correlation': [target_corr[feat] for feat in top_corr.index]\n",
        "}))\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "colors = ['red' if x < 0 else 'green' for x in [target_corr[feat] for feat in top_corr.index]]\n",
        "bars = ax.barh(range(len(top_corr)), [target_corr[feat] for feat in top_corr.index], color=colors, alpha=0.7)\n",
        "ax.set_yticks(range(len(top_corr)))\n",
        "ax.set_yticklabels(top_corr.index)\n",
        "ax.set_title('Top 10 Features Correlated with Cancellation', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Correlation Coefficient')\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Time-based Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancellation rate by month\n",
        "print(\"=== Cancellation Rate by Arrival Month ===\")\n",
        "month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
        "              'July', 'August', 'September', 'October', 'November', 'December']\n",
        "df['arrival_date_month'] = pd.Categorical(df['arrival_date_month'], categories=month_order, ordered=True)\n",
        "\n",
        "month_cancel = df.groupby('arrival_date_month')['is_canceled'].agg(['count', 'sum', 'mean']).reset_index()\n",
        "month_cancel.columns = ['month', 'total_bookings', 'cancelled', 'cancellation_rate']\n",
        "month_cancel['cancellation_rate'] = month_cancel['cancellation_rate'] * 100\n",
        "display(month_cancel)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.plot(month_cancel['month'], month_cancel['cancellation_rate'], \n",
        "       marker='o', linewidth=2, markersize=8, color='crimson')\n",
        "ax.set_title('Cancellation Rate by Arrival Month', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Cancellation Rate (%)')\n",
        "ax.set_xlabel('Month')\n",
        "plt.xticks(rotation=45)\n",
        "ax.grid(True, alpha=0.3)\n",
        "for i, (month, rate) in enumerate(zip(month_cancel['month'], month_cancel['cancellation_rate'])):\n",
        "    ax.text(i, rate + 1, f'{rate:.1f}%', ha='center', va='bottom', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Key Insights Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n1. TARGET DISTRIBUTION:\")\n",
        "print(f\"   - Overall cancellation rate: {df['is_canceled'].mean()*100:.2f}%\")\n",
        "print(f\"   - Class imbalance: {'Yes' if abs(df['is_canceled'].mean() - 0.5) < 0.1 else 'No'}\")\n",
        "\n",
        "print(\"\\n2. TOP FACTORS INFLUENCING CANCELLATION:\")\n",
        "if 'deposit_type' in df.columns:\n",
        "    deposit_high = df.groupby('deposit_type')['is_canceled'].mean().idxmax()\n",
        "    print(f\"   - Deposit Type: {deposit_high} has highest cancellation rate\")\n",
        "if 'lead_time' in df.columns:\n",
        "    high_lead = df[df['lead_time'] > 180]['is_canceled'].mean()\n",
        "    low_lead = df[df['lead_time'] <= 30]['is_canceled'].mean()\n",
        "    print(f\"   - Lead Time: Long lead times (>180 days) have {high_lead*100:.1f}% cancellation vs {low_lead*100:.1f}% for short lead times\")\n",
        "\n",
        "print(\"\\n3. DATA QUALITY:\")\n",
        "missing_cols = df.isnull().sum()\n",
        "missing_cols = missing_cols[missing_cols > 0]\n",
        "if len(missing_cols) > 0:\n",
        "    print(f\"   - Columns with missing values: {len(missing_cols)}\")\n",
        "    print(f\"   - Most missing: {missing_cols.idxmax()} ({missing_cols.max()} values)\")\n",
        "else:\n",
        "    print(\"   - No missing values found\")\n",
        "\n",
        "print(\"\\n4. FEATURE ENGINEERING OPPORTUNITIES:\")\n",
        "print(\"   - Create total_nights from weekend + weekday nights\")\n",
        "print(\"   - Create total_guests from adults + children + babies\")\n",
        "print(\"   - Extract date features (day of week, season)\")\n",
        "print(\"   - Create lead_time categories\")\n",
        "print(\"   - Calculate booking value (ADR × nights)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✓ Comprehensive EDA completed\n",
        "✓ Key patterns and relationships identified\n",
        "✓ Insights extracted for feature engineering\n",
        "✓ Data quality assessed\n",
        "\n",
        "**Next Steps**: Proceed to `03_spark_preprocessing.ipynb` for Spark-based data processing and feature engineering.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
