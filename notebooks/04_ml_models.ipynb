{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Machine Learning Models\n",
    "\n",
    "This notebook trains multiple machine learning models to predict hotel booking cancellations:\n",
    "1. Naive Bayes\n",
    "2. Decision Tree\n",
    "\n",
    "All models are trained using PySpark MLlib for distributed processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✓ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Install PySpark if not already installed\n",
    "%pip install pyspark findspark -q\n",
    "\n",
    "# Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import (\n",
    "    NaiveBayes, DecisionTreeClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Spark and Load Data\n",
    "\n",
    "**Note**: This notebook assumes you've run the previous preprocessing notebook. If not, run `03_spark_preprocessing.ipynb` first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Spark session...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/30 20:57:08 WARN Utils: Your hostname, Abdelrahmans-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.18 instead (on interface en0)\n",
      "25/12/30 20:57:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/30 20:57:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/30 20:57:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New Spark session created\n",
      "Spark version: 4.1.0\n",
      "Working directory: /Users/abdelrahman/Developer/Hotel Booking Cancellation Prediction/notebooks\n",
      "\n",
      "Looking for data in: /Users/abdelrahman/Developer/Hotel Booking Cancellation Prediction/data/processed_data\n",
      "✓ Data loaded from Parquet files\n",
      "  - Training set: 95,673 records\n",
      "  - Test set: 23,717 records\n"
     ]
    }
   ],
   "source": [
    "# Create or get existing Spark session\n",
    "# Handle Spark initialization more robustly\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Check if spark exists and is valid\n",
    "    spark\n",
    "    # Test if spark is actually working\n",
    "    spark.sparkContext.getConf().get(\"spark.app.name\")\n",
    "    print(\"✓ Using existing Spark session\")\n",
    "except (NameError, AttributeError, Exception) as e:\n",
    "    # Create new Spark session\n",
    "    print(\"Creating new Spark session...\")\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"HotelBookingML\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.memory\", \"4g\") \\\n",
    "            .getOrCreate()\n",
    "        spark.sparkContext.setLogLevel(\"WARN\")\n",
    "        print(\"✓ New Spark session created\")\n",
    "        print(f\"Spark version: {spark.version}\")\n",
    "    except Exception as spark_error:\n",
    "        print(f\"⚠ ERROR: Failed to create Spark session: {spark_error}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(\"1. Make sure PySpark is installed: !pip install pyspark\")\n",
    "        print(\"2. Restart the runtime: Runtime -> Restart runtime\")\n",
    "        print(\"3. Run this cell again\")\n",
    "        raise\n",
    "\n",
    "# Load processed data from previous notebook\n",
    "# If running notebooks separately, data is saved as Parquet files\n",
    "\n",
    "# Set paths for data\n",
    "import os\n",
    "\n",
    "# Use relative path from notebook location\n",
    "save_dir = os.path.join(\"..\", \"data\", \"processed_data\")\n",
    "save_dir = os.path.abspath(save_dir)  # Convert to absolute path\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "train_path = os.path.join(save_dir, \"train_data.parquet\")\n",
    "test_path = os.path.join(save_dir, \"test_data.parquet\")\n",
    "\n",
    "print(f\"\\nLooking for data in: {save_dir}\")\n",
    "\n",
    "try:\n",
    "    # Try to load from saved Parquet files (when running notebooks separately)\n",
    "    if os.path.exists(save_dir):\n",
    "        train_df = spark.read.parquet(train_path)\n",
    "        test_df = spark.read.parquet(test_path)\n",
    "        print(f\"✓ Data loaded from Parquet files\")\n",
    "        print(f\"  - Training set: {train_df.count():,} records\")\n",
    "        print(f\"  - Test set: {test_df.count():,} records\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Directory {save_dir} does not exist\")\n",
    "except Exception as e:\n",
    "    # If Parquet files don't exist, try to use variables from previous notebook\n",
    "    try:\n",
    "        train_df\n",
    "        test_df\n",
    "        print(\"\\n✓ Using train_df and test_df from previous notebook\")\n",
    "        print(f\"  - Training set: {train_df.count():,} records\")\n",
    "        print(f\"  - Test set: {test_df.count():,} records\")\n",
    "    except NameError:\n",
    "        print(\"\\n⚠ ERROR: Could not find processed data!\")\n",
    "        print(f\"\\nPossible issues:\")\n",
    "        print(f\"1. Parquet files not found at: {save_dir}\")\n",
    "        print(f\"2. Previous notebook variables not available\")\n",
    "        print(f\"\\nSolution:\")\n",
    "        print(f\"  - Run '03_spark_preprocessing.ipynb' first\")\n",
    "        print(f\"  - Make sure Cell 27 in preprocessing notebook completed successfully\")\n",
    "        print(f\"  - Check that data was saved to: {save_dir}\")\n",
    "        print(f\"\\nError details: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Training Functions\n",
    "\n",
    "Define functions to train and evaluate models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model training functions defined\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_for_naive_bayes(df):\n",
    "    \"\"\"\n",
    "    Prepare data for Naive Bayes by scaling features to [0, 1] range.\n",
    "    Naive Bayes requires non-negative feature values.\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import ArrayType, DoubleType\n",
    "    from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "    \n",
    "    # Extract features vector to scale\n",
    "    # MinMaxScaler scales features to [0, 1] range, ensuring non-negative values\n",
    "    scaler = MinMaxScaler(\n",
    "        inputCol=\"features\",\n",
    "        outputCol=\"features_scaled\",\n",
    "        min=0.0,\n",
    "        max=1.0\n",
    "    )\n",
    "    \n",
    "    # Fit scaler on training data and transform\n",
    "    scaler_model = scaler.fit(df)\n",
    "    df_scaled = scaler_model.transform(df)\n",
    "    \n",
    "    # Clip values to [0, 1] to handle any out-of-range values from test data\n",
    "    # This ensures all values are non-negative for Naive Bayes\n",
    "    def clip_vector(v):\n",
    "        \"\"\"Clip vector values to [0, 1] range.\"\"\"\n",
    "        values = v.toArray()\n",
    "        clipped = [max(0.0, min(1.0, val)) for val in values]\n",
    "        return Vectors.dense(clipped)\n",
    "    \n",
    "    clip_udf = udf(clip_vector, VectorUDT())\n",
    "    df_scaled = df_scaled.withColumn(\"features\", clip_udf(col(\"features_scaled\"))).drop(\"features_scaled\")\n",
    "    \n",
    "    return df_scaled, scaler_model\n",
    "\n",
    "def train_naive_bayes(train_df):\n",
    "    \"\"\"Train Naive Bayes model.\"\"\"\n",
    "    print(\"Training Naive Bayes...\")\n",
    "    print(\"  - Scaling features to [0, 1] range (Naive Bayes requires non-negative values)...\")\n",
    "    \n",
    "    # Scale features to make them non-negative\n",
    "    train_df_scaled, scaler_model = prepare_data_for_naive_bayes(train_df)\n",
    "    \n",
    "    # Train Naive Bayes on scaled features\n",
    "    nb = NaiveBayes(\n",
    "        featuresCol='features',\n",
    "        labelCol='label'\n",
    "    )\n",
    "    model = nb.fit(train_df_scaled)\n",
    "    print(\"✓ Naive Bayes trained\")\n",
    "    return model, scaler_model\n",
    "\n",
    "def train_decision_tree(train_df, max_depth=10, max_bins=256):\n",
    "    \"\"\"\n",
    "    Train Decision Tree model.\n",
    "    \n",
    "    Args:\n",
    "        train_df: Training DataFrame\n",
    "        max_depth: Maximum depth of the tree (default: 10)\n",
    "        max_bins: Maximum number of bins for discretizing continuous features\n",
    "                  Must be at least as large as the number of values in any categorical feature\n",
    "                  (default: 256 to handle high-cardinality categorical features)\n",
    "    \"\"\"\n",
    "    print(\"Training Decision Tree...\")\n",
    "    print(f\"  - maxDepth: {max_depth}, maxBins: {max_bins}\")\n",
    "    dt = DecisionTreeClassifier(\n",
    "        featuresCol='features',\n",
    "        labelCol='label',\n",
    "        maxDepth=max_depth,\n",
    "        maxBins=max_bins,  # Increased to handle high-cardinality categorical features\n",
    "        impurity='gini'\n",
    "    )\n",
    "    model = dt.fit(train_df)\n",
    "    print(\"✓ Decision Tree trained\")\n",
    "    return model\n",
    "\n",
    "print(\"✓ Model training functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(predictions, model_name):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    # Binary classification evaluator for AUC\n",
    "    binary_evaluator = BinaryClassificationEvaluator(\n",
    "        labelCol='label',\n",
    "        rawPredictionCol='rawPrediction',\n",
    "        metricName='areaUnderROC'\n",
    "    )\n",
    "    \n",
    "    # Multiclass evaluator for other metrics\n",
    "    multiclass_evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='label',\n",
    "        predictionCol='prediction',\n",
    "        metricName='accuracy'\n",
    "    )\n",
    "    \n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        'accuracy': multiclass_evaluator.evaluate(predictions),\n",
    "        'auc': binary_evaluator.evaluate(predictions)\n",
    "    }\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    for metric_name in ['weightedPrecision', 'weightedRecall', 'f1']:\n",
    "        evaluator = MulticlassClassificationEvaluator(\n",
    "            labelCol='label',\n",
    "            predictionCol='prediction',\n",
    "            metricName=metric_name\n",
    "        )\n",
    "        metrics[metric_name] = evaluator.evaluate(predictions)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"✓ Evaluation function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Model 1 - Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes...\n",
      "  - Scaling features to [0, 1] range (Naive Bayes requires non-negative values)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Naive Bayes trained\n",
      "  - Scaling test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/30 20:57:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes Results ===\n",
      "Accuracy: 0.7709\n",
      "Auc: 0.4942\n",
      "Weightedprecision: 0.8257\n",
      "Weightedrecall: 0.7709\n",
      "F1: 0.7382\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes\n",
    "nb_model, nb_scaler = train_naive_bayes(train_df)\n",
    "\n",
    "# Scale test data using the same scaler fitted on training data\n",
    "print(\"  - Scaling test data...\")\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# Transform test data\n",
    "test_df_scaled = nb_scaler.transform(test_df)\n",
    "\n",
    "# Clip values to [0, 1] to handle any out-of-range values\n",
    "def clip_vector(v):\n",
    "    \"\"\"Clip vector values to [0, 1] range.\"\"\"\n",
    "    values = v.toArray()\n",
    "    clipped = [max(0.0, min(1.0, val)) for val in values]\n",
    "    return Vectors.dense(clipped)\n",
    "\n",
    "clip_udf = udf(clip_vector, VectorUDT())\n",
    "test_df_scaled = test_df_scaled.withColumn(\"features\", clip_udf(col(\"features_scaled\"))).drop(\"features_scaled\")\n",
    "\n",
    "# Make predictions on scaled test data\n",
    "nb_predictions = nb_model.transform(test_df_scaled)\n",
    "\n",
    "# Evaluate\n",
    "nb_metrics = evaluate_model(nb_predictions, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n=== Naive Bayes Results ===\")\n",
    "for metric, value in nb_metrics.items():\n",
    "    if metric != 'model':\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Predictions ===\n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|    1|       0.0|[0.78765659530828...|\n",
      "|    1|       1.0|[0.13344172323286...|\n",
      "|    1|       1.0|[0.38538517338815...|\n",
      "|    0|       0.0|[0.93500605987029...|\n",
      "|    0|       0.0|[0.90982296594122...|\n",
      "|    0|       0.0|[0.88433900542598...|\n",
      "|    0|       0.0|[0.91784373778433...|\n",
      "|    0|       0.0|[0.88634665148152...|\n",
      "|    0|       0.0|[0.89232141611945...|\n",
      "|    0|       0.0|[0.91506695796855...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/abdelrahman/Developer/Hotel Booking Cancellation Prediction/venv/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "  File \"/Users/abdelrahman/Developer/Hotel Booking Cancellation Prediction/venv/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "print(\"\\n=== Sample Predictions ===\")\n",
    "nb_predictions.select(\"label\", \"prediction\", \"probability\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Model 2 - Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "  - maxDepth: 10, maxBins: 256\n",
      "✓ Decision Tree trained\n",
      "\n",
      "=== Decision Tree Results ===\n",
      "Accuracy: 0.8390\n",
      "Auc: 0.8581\n",
      "Weightedprecision: 0.8390\n",
      "Weightedrecall: 0.8390\n",
      "F1: 0.8390\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree\n",
    "dt_model = train_decision_tree(train_df, max_depth=10)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "# Evaluate\n",
    "dt_metrics = evaluate_model(dt_predictions, \"Decision Tree\")\n",
    "\n",
    "print(\"\\n=== Decision Tree Results ===\")\n",
    "for metric, value in dt_metrics.items():\n",
    "    if metric != 'model':\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Decision Tree Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 10 Most Important Features (Decision Tree) ===\n",
      "Feature 25: 0.4414\n",
      "Feature 0: 0.1046\n",
      "Feature 20: 0.0859\n",
      "Feature 13: 0.0837\n",
      "Feature 17: 0.0761\n",
      "Feature 21: 0.0739\n",
      "Feature 12: 0.0429\n",
      "Feature 1: 0.0337\n",
      "Feature 26: 0.0192\n",
      "Feature 18: 0.0070\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree feature importance (if available)\n",
    "try:\n",
    "    feature_importance = dt_model.featureImportances\n",
    "    print(\"\\n=== Top 10 Most Important Features (Decision Tree) ===\")\n",
    "    # Note: Feature names would need to be mapped from indices\n",
    "    # This is a simplified version\n",
    "    importances = feature_importance.toArray()\n",
    "    top_indices = np.argsort(importances)[-10:][::-1]\n",
    "    for idx in top_indices:\n",
    "        print(f\"Feature {idx}: {importances[idx]:.4f}\")\n",
    "except:\n",
    "    print(\"Feature importance not available for this model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Comparison ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>weightedPrecision</th>\n",
       "      <th>weightedRecall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.7709</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.8257</td>\n",
       "      <td>0.7709</td>\n",
       "      <td>0.7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy     auc  weightedPrecision  weightedRecall      f1\n",
       "model                                                                     \n",
       "Naive Bayes      0.7709  0.4942             0.8257          0.7709  0.7382\n",
       "Decision Tree    0.8390  0.8581             0.8390          0.8390  0.8390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect all metrics\n",
    "all_metrics = [nb_metrics, dt_metrics]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df = metrics_df.set_index('model')\n",
    "\n",
    "print(\"=== Model Comparison ===\")\n",
    "display(metrics_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All models trained and evaluated\n",
      "\n",
      "Models and predictions available:\n",
      "  - nb_model, nb_predictions, nb_metrics\n",
      "  - dt_model, dt_predictions, dt_metrics\n",
      "  - metrics_df (comparison table)\n",
      "\n",
      "✓ Metrics saved to /Users/abdelrahman/Developer/Hotel Booking Cancellation Prediction/data/model_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions for evaluation notebook\n",
    "# Store predictions in variables for next notebook\n",
    "print(\"✓ All models trained and evaluated\")\n",
    "print(\"\\nModels and predictions available:\")\n",
    "print(\"  - nb_model, nb_predictions, nb_metrics\")\n",
    "print(\"  - dt_model, dt_predictions, dt_metrics\")\n",
    "print(\"  - metrics_df (comparison table)\")\n",
    "\n",
    "# Save metrics to CSV for report\n",
    "import os\n",
    "\n",
    "# Use relative path from notebook location\n",
    "metrics_path = os.path.join(\"..\", \"data\", \"model_metrics.csv\")\n",
    "metrics_path = os.path.abspath(metrics_path)  # Convert to absolute path\n",
    "\n",
    "metrics_df.to_csv(metrics_path)\n",
    "print(f\"\\n✓ Metrics saved to {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✓ Naive Bayes trained and evaluated\n",
    "✓ Decision Tree trained and evaluated\n",
    "✓ Model comparison completed\n",
    "\n",
    "**Next Steps**: Proceed to `05_evaluation_visualization.ipynb` for detailed evaluation and visualizations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
